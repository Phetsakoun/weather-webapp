import sys, os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

import joblib
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Input, LSTM, Dense
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from data_loader import load_weather_data
from preprocess import prepare_data

# ‡∏ï‡∏±‡πâ‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•
BASE_DIR  = os.path.dirname(os.path.dirname(__file__))
MODEL_DIR = os.path.join(BASE_DIR, "model")
os.makedirs(MODEL_DIR, exist_ok=True)

if __name__ == "__main__":
    SEQ_LEN = 24
    EPOCHS  = 50  # ‡∏•‡∏î epochs ‡πÉ‡∏´‡πâ‡∏ô‡πâ‡∏≠‡∏¢‡∏•‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ù‡∏∂‡∏Å‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
    BATCH   = 32

    try:
        # 1) Load & preprocess
        print("üîÑ Loading weather data from database...")
        data = load_weather_data()  # shape (n, 5) - ‡πÄ‡∏û‡∏¥‡πà‡∏° rainfall
        print(f"‚úÖ Loaded weather data: {data.shape}")
        
        if len(data) < SEQ_LEN + 1:
            print(f"‚ùå Error: Not enough data. Need at least {SEQ_LEN + 1} records, got {len(data)}")
            exit(1)
        
        print("üîÑ Preparing sequences...")
        X, y, scaler = prepare_data(data, SEQ_LEN)  # X: (samples, SEQ_LEN, 5), y: (samples, 5)
        print(f"‚úÖ Shape X: {X.shape}, y: {y.shape}")

        # 2) Split
        split = int(len(X) * 0.8)
        X_train, X_val = X[:split], X[split:]
        y_train, y_val = y[:split], y[split:]
        print(f"üìä Training samples: {len(X_train)}, Validation samples: {len(X_val)}")

        # 3) Build model
        print("üèóÔ∏è Building LSTM model...")
        model = Sequential([
            Input(shape=(SEQ_LEN, 5)),  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô 5 features
            LSTM(50, return_sequences=True),  # ‡πÄ‡∏û‡∏¥‡πà‡∏° LSTM layer
            LSTM(50),
            Dense(25, activation='relu'),  # ‡πÄ‡∏û‡∏¥‡πà‡∏° hidden layer
            Dense(5)  # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ temp, hum, pres, wind_speed, rainfall
        ])
        model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])
        print("‚úÖ Model compiled successfully")
        print(model.summary())

    # 4) Callbacks
    checkpoint = ModelCheckpoint(
        filepath=os.path.join(MODEL_DIR, "lstm_weather.keras"),
        monitor="val_loss", save_best_only=True, verbose=1
    )
    earlystop = EarlyStopping(
        monitor="val_loss", patience=10, restore_best_weights=True, verbose=1
    )

    # 5) Train
    print("üöÄ Starting training...")
    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=EPOCHS, batch_size=BATCH,
        callbacks=[checkpoint, earlystop],
        verbose=1
    )
    print("‚úÖ Training completed!")

    # 6) Save scaler
    scaler_path = os.path.join(MODEL_DIR, "scaler.pkl")
    joblib.dump(scaler, scaler_path)
    print(f"üíæ Scaler saved to: {scaler_path}")
    
    # 7) Save model in modern format
    model_path = os.path.join(MODEL_DIR, "lstm_weather.keras")
    model.save(model_path)
    print(f"üíæ Model saved to: {model_path}")
    
    # 8) Print training summary
    print("\nüìä Training Summary:")
    print(f"Final Training Loss: {history.history['loss'][-1]:.4f}")
    print(f"Final Validation Loss: {history.history['val_loss'][-1]:.4f}")
    print(f"Best Validation Loss: {min(history.history['val_loss']):.4f}")
    print("üéâ Model training completed successfully!")
        
    except Exception as e:
        print(f"‚ùå Error during training: {str(e)}")
        import traceback
        print("üìÑ Full error traceback:")
        traceback.print_exc()
        exit(1)
